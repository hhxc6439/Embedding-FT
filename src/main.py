#!/usr/bin/env python3
"""
ä¸“åˆ© RAG embedding æ¨¡å‹å¾®è°ƒä¸»ç¨‹åºã€‚é»˜è®¤ bge-base-zh-v1.5ï¼Œæ‘˜è¦â†’LLMâ†’queryï¼Œæ­£æ ·æœ¬ä¸ºæ‘˜è¦ï¼Œè´Ÿæ ·æœ¬ä¸ºåŒå¤§ç»„ä¸åŒå°ç»„ã€‚
"""

import os
import sys
import json
import logging
import argparse
import time
from pathlib import Path
from typing import List, Optional
from tqdm import tqdm
import torch

print(f"CUDA_VISIBLE_DEVICES ç¯å¢ƒå˜é‡: {os.environ.get('CUDA_VISIBLE_DEVICES')}")
print(f"PyTorch å¯è§è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
print(f"PyTorch å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
print(f"PyTorch è®¾å¤‡åç§°: {torch.cuda.get_device_name()}")

_src_dir = Path(__file__).resolve().parent
_project_root = _src_dir.parent
if str(_src_dir) not in sys.path:
    sys.path.insert(0, str(_src_dir))
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))

from config import Config
from data_loader import PatentDataLoader, create_data_loader
from query_generator import create_query_generator
from negative_sampler import create_negative_sampler
from dataset_builder import DatasetBuilder, PatentDataset
from model import create_model, PatentEmbeddingModel
from trainer import create_trainer


def _get_query_cache_path(config):
    return os.path.join(
        config.data.processed_data_dir,
        getattr(config.query, "query_cache_filename", "llm_queries_cache.json"),
    )


def _load_query_cache(config, patents) -> Optional[List[dict]]:
    """è‹¥å¯ç”¨ç¼“å­˜ä¸”å­˜åœ¨ä¸å½“å‰ patent é›†åˆä¸€è‡´çš„ç¼“å­˜ï¼Œåˆ™è¿”å› queries åˆ—è¡¨ï¼ˆä¸ patents åŒåºï¼‰ï¼Œå¦åˆ™è¿”å› Noneã€‚"""
    if not getattr(config.query, "use_query_cache", True):
        return None
    path = _get_query_cache_path(config)
    if not os.path.exists(path):
        return None
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception:
        return None
    by_id = data.get("queries_by_id") or {}
    current_ids = {p.id for p in patents}
    if set(by_id.keys()) != current_ids:
        return None
    out = []
    for p in patents:
        q = by_id.get(p.id)
        if not q:
            return None
        out.append(q)
    return out


def _save_query_cache(config, patents, queries):
    """å°† queries æŒ‰ patent_id ç´¢å¼•åå†™å…¥ç¼“å­˜ã€‚"""
    use = getattr(config.query, "use_query_cache", True)
    if not use:
        return
    path = _get_query_cache_path(config)
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    by_id = {q["patent_id"]: q for q in queries}
    payload = {"patent_ids": [p.id for p in patents], "queries_by_id": by_id}
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)


class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""

    def __init__(self, total_steps=8):
        self.total_steps = total_steps
        self.current_step = 0
        self.start_time = time.time()
        self.step_times = []

    def start_step(self, step_name: str):
        """å¼€å§‹ä¸€ä¸ªæ–°æ­¥éª¤"""
        self.current_step += 1
        step_start = time.time()
        print(f"\n{'=' * 60}")
        print(f"æ­¥éª¤ {self.current_step}/{self.total_steps}: {step_name}")
        print(f"{'=' * 60}")
        return step_start

    def end_step(self, step_start: float, message: str = ""):
        """ç»“æŸå½“å‰æ­¥éª¤"""
        step_time = time.time() - step_start
        self.step_times.append(step_time)

        if message:
            print(f"âœ“ {message}")
        print(f"â±ï¸  æ­¥éª¤è€—æ—¶: {step_time:.1f}ç§’")
        print(f"{'=' * 60}")

    def summary(self):
        """æ‰“å°æ€»ç»“"""
        total_time = time.time() - self.start_time
        print(f"\n{'=' * 60}")
        print("ğŸ‰ æ‰€æœ‰æ­¥éª¤å®Œæˆ!")
        print(f"{'=' * 60}")
        print(f"æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time / 60:.1f}åˆ†é’Ÿ)")
        print(f"å¹³å‡æ¯æ­¥è€—æ—¶: {total_time / self.total_steps:.1f}ç§’")
        print(f"{'=' * 60}")


# è®¾ç½®æ—¥å¿—
def setup_logging(log_dir: str, level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    log_dir = Path(log_dir)
    log_dir.mkdir(parents=True, exist_ok=True)

    log_file = log_dir / "training.log"

    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    date_format = "%Y-%m-%d %H:%M:%S"

    # åˆ›å»ºæ—¥å¿—å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(logging.Formatter(log_format, date_format))

    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(log_format, date_format))

    # é…ç½®æ ¹æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, level),
        handlers=[file_handler, console_handler]
    )

    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
    logging.getLogger("transformers").setLevel(logging.WARNING)
    logging.getLogger("torch").setLevel(logging.WARNING)

    return log_file


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ä¸“åˆ©embeddingæ¨¡å‹å¾®è°ƒ")

    # æ•°æ®è·¯å¾„
    parser.add_argument("--data_dir", type=str,
                        help="ä¸“åˆ©æ•°æ®ç›®å½•ï¼ˆåŒ…å«jsonæ–‡ä»¶ï¼‰")
    parser.add_argument("--output_dir", type=str,
                        help="è¾“å‡ºç›®å½•")

    # æ¨¡å‹é…ç½®
    parser.add_argument("--model_name", type=str,
                        help="åŸºç¡€æ¨¡å‹åç§°æˆ–è·¯å¾„")
    parser.add_argument("--use_lora", action="store_true",
                        help="æ˜¯å¦ä½¿ç”¨LoRAå¾®è°ƒ")

    # è®­ç»ƒé…ç½®
    parser.add_argument("--batch_size", type=int,
                        help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--learning_rate", type=float,
                        help="å­¦ä¹ ç‡")
    parser.add_argument("--num_epochs", type=int,
                        help="è®­ç»ƒè½®æ•°")

    # è´Ÿæ ·æœ¬ç­–ç•¥
    parser.add_argument("--negative_strategy", type=str,
                        choices=["optimized_mixed", "same_group_priority",
                                 "same_subclass_different_group", "mixed", "random", "hard"],
                        help="è´Ÿæ ·æœ¬é‡‡æ ·ç­–ç•¥")
    parser.add_argument("--negatives_per_positive", type=int,
                        help="æ¯ä¸ªæ­£æ ·æœ¬çš„è´Ÿæ ·æœ¬æ•°")

    # æŸ¥è¯¢ç”Ÿæˆï¼ˆé»˜è®¤æœ¬åœ° LLMï¼›--use_api_llm æ—¶æ”¹ç”¨ APIï¼Œkey å¯ç”¨ --llm_api_key æˆ– env OPENAI_API_KEYï¼‰
    parser.add_argument("--use_llm", action="store_true",
                        help="ä½¿ç”¨ LLM ç”ŸæˆæŸ¥è¯¢")
    parser.add_argument("--use_api_llm", action="store_true",
                        help="ä½¿ç”¨ API å‹ LLM ç”ŸæˆæŸ¥è¯¢ï¼ˆè¦†ç›–æœ¬åœ° LLMï¼‰")
    parser.add_argument("--llm_api_key", type=str,
                        help="LLM API å¯†é’¥ï¼ˆä¸æŒ‡å®šæ—¶å¯ä»ç¯å¢ƒå˜é‡ OPENAI_API_KEY è¯»å–ï¼‰")

    # å…¶ä»–
    parser.add_argument("--max_samples", type=int,
                        help="æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    parser.add_argument("--use_cache", action="store_true", default=True,
                        help="ä½¿ç”¨æ•°æ®é›†ç¼“å­˜")
    parser.add_argument("--no_query_cache", action="store_true",
                        help="ç¦ç”¨ LLM query ç¼“å­˜ï¼ˆæ¯æ¬¡é‡æ–°ç”Ÿæˆï¼‰")
    parser.add_argument("--test_only", action="store_true",
                        help="ä»…æµ‹è¯•ï¼Œä¸è®­ç»ƒ")
    parser.add_argument("--resume", type=str,
                        help="ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
    parser.add_argument("--checkpoint_every_n_epochs", type=int,
                        help="æ¯ N ä¸ª epoch ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ï¼ˆé»˜è®¤ 1ï¼‰")
    parser.add_argument("--log_level", type=str, default="INFO",
                        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                        help="æ—¥å¿—çº§åˆ«")
    parser.add_argument("--quick_test", action="store_true",
                        help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå°æ•°æ®é›†ï¼‰")
    parser.add_argument("--recommended", action="store_true",
                        help="ä½¿ç”¨ç»éªŒæ¨èè®­ç»ƒè¶…å‚æ•°ï¼ˆè§ READMEï¼‰")

    return parser.parse_args()


def update_config_from_args(config: Config, args: argparse.Namespace):
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®"""
    if args.data_dir:
        data_dir = os.path.normpath(os.path.abspath(args.data_dir))
        config.data.raw_data_dir = data_dir
        config.data.processed_data_dir = os.path.join(data_dir, "processed")

    if args.output_dir:
        out_dir = os.path.normpath(os.path.abspath(args.output_dir))
        config.experiment.output_dir = out_dir
        config.experiment.log_dir = os.path.join(out_dir, "logs")

    if args.model_name:
        config.model.base_model_name = args.model_name

    if args.use_lora:
        config.model.use_lora = args.use_lora

    if args.batch_size:
        config.training.batch_size = args.batch_size

    if args.learning_rate:
        config.training.learning_rate = args.learning_rate

    if args.num_epochs:
        config.training.num_epochs = args.num_epochs

    if args.negative_strategy:
        config.negative.strategy = args.negative_strategy

    if args.negatives_per_positive:
        config.negative.negatives_per_positive = args.negatives_per_positive

    if args.use_llm:
        config.query.use_llm = args.use_llm
    if getattr(args, "use_api_llm", False):
        config.query.local_model_enabled = False
        config.query.use_llm = True
    key = getattr(args, "llm_api_key", None) or os.environ.get("OPENAI_API_KEY")
    if key:
        config.query.llm_api_key = key

    if args.max_samples:
        config.data.max_samples = args.max_samples
    if getattr(args, "no_query_cache", False):
        config.query.use_query_cache = False
    if getattr(args, "checkpoint_every_n_epochs", None) is not None:
        config.training.checkpoint_every_n_epochs = args.checkpoint_every_n_epochs

    # ç»éªŒæ¨èè¶…å‚æ•°
    if getattr(args, "recommended", False):
        print("ğŸ“ ä½¿ç”¨ç»éªŒæ¨èè®­ç»ƒè¶…å‚æ•°")
        config.training.batch_size = 32
        config.training.learning_rate = 2e-5
        config.training.num_epochs = 5
        config.training.warmup_ratio = 0.1
        config.training.weight_decay = 0.01
        config.training.loss_type = "triplet"
        config.training.margin = 0.3
        config.training.temperature = 0.05
        config.training.early_stopping_patience = 3
        config.training.eval_steps = 100
        config.training.save_steps = 500
        config.training.checkpoint_every_n_epochs = 1
        config.model.use_lora = True
        config.model.lora_r = 16
        config.model.lora_alpha = 32
        config.model.lora_dropout = 0.1

    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick_test:
        config.data.max_samples = 100
        config.training.num_epochs = 2
        config.training.batch_size = 4
        print("ğŸ”§ å¯ç”¨å¿«é€Ÿæµ‹è¯•æ¨¡å¼")

    return config


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()

    # åˆ›å»ºæ–°çš„é…ç½®å®ä¾‹å¹¶æ›´æ–°
    config = Config()
    config = update_config_from_args(config, args)

    # è®¾ç½®æ—¥å¿—
    log_file = setup_logging(config.experiment.log_dir, args.log_level)
    logger = logging.getLogger(__name__)

    # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
    tracker = ProgressTracker(total_steps=7 if args.test_only else 8)

    logger.info("=" * 60)
    logger.info("ğŸš€ ä¸“åˆ©embeddingæ¨¡å‹å¾®è°ƒ")
    logger.info("=" * 60)

    # æ‰“å°é…ç½®ä¿¡æ¯
    logger.info("ğŸ“‹ é…ç½®ä¿¡æ¯:")
    logger.info(f"  æ•°æ®ç›®å½•: {config.data.raw_data_dir}")
    logger.info(f"  è¾“å‡ºç›®å½•: {config.experiment.output_dir}")
    logger.info(f"  æ¨¡å‹åç§°: {config.model.base_model_name}")
    logger.info(f"  LoRAå¾®è°ƒ: {config.model.use_lora}")
    logger.info(f"  æ‰¹æ¬¡å¤§å°: {config.training.batch_size}")
    logger.info(f"  å­¦ä¹ ç‡: {config.training.learning_rate}")
    logger.info(f"  è®­ç»ƒè½®æ•°: {config.training.num_epochs}")
    logger.info(f"  è´Ÿæ ·æœ¬ç­–ç•¥: {config.negative.strategy}")
    logger.info(f"  è´Ÿæ ·æœ¬æ•°: {config.negative.negatives_per_positive}")
    logger.info(f"  LLMç”ŸæˆæŸ¥è¯¢: {config.query.use_llm}ï¼ˆæœ¬åœ°: {getattr(config.query, 'local_model_enabled', False)}ï¼‰")
    logger.info(f"  Query ç¼“å­˜: {'å¼€' if getattr(config.query, 'use_query_cache', True) else 'å…³'}")
    logger.info(f"  æ¯ N epoch ä¿å­˜ checkpoint: {getattr(config.training, 'checkpoint_every_n_epochs', 1)}")
    logger.info(f"  æ—¥å¿—æ–‡ä»¶: {log_file}")
    logger.info("=" * 60)

    try:
        # 1. åŠ è½½ä¸“åˆ©æ•°æ®
        step_start = tracker.start_step("åŠ è½½ä¸“åˆ©æ•°æ®")
        logger.info("å¼€å§‹åŠ è½½ä¸“åˆ©æ•°æ®...")

        data_loader = create_data_loader(config, load_existing=args.use_cache)

        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„æ•°æ®
        if not data_loader.patents or not args.use_cache:
            patents = data_loader.load_from_folder(
                config.data.raw_data_dir,
                max_samples=config.data.max_samples
            )
            data_loader.process_patents(patents)
        else:
            logger.info("ä½¿ç”¨å·²åŠ è½½çš„ç¼“å­˜æ•°æ®")

        logger.info(f"âœ… åŠ è½½äº† {len(data_loader.patents)} ä¸ªä¸“åˆ©")
        tracker.end_step(step_start, f"åŠ è½½äº† {len(data_loader.patents)} ä¸ªä¸“åˆ©")

        # 2. ç”ŸæˆæŸ¥è¯¢ï¼ˆä¼˜å…ˆå¤ç”¨å·²ä¿å­˜çš„ LLM query ç¼“å­˜ï¼‰
        step_start = tracker.start_step("ç”ŸæˆæŸ¥è¯¢")
        logger.info("å¼€å§‹ç”ŸæˆæŸ¥è¯¢...")

        query_generator = create_query_generator(config)
        cached = _load_query_cache(config, data_loader.patents)
        if cached is not None:
            queries = cached
            logger.info(f"ğŸ“‚ å¤ç”¨å·²ä¿å­˜çš„ query ç¼“å­˜ï¼ˆ{len(queries)} æ¡ï¼‰")
        else:
            use_llm = getattr(config.query, "local_model_enabled", False) or (
                config.query.use_llm and bool(config.query.llm_api_key)
            )
            if getattr(config.query, "local_model_enabled", False):
                logger.info("ğŸ¤– ä½¿ç”¨æœ¬åœ° LLM ç”ŸæˆæŸ¥è¯¢")
            elif config.query.use_llm and config.query.llm_api_key:
                logger.info("ğŸ¤– ä½¿ç”¨ LLM API ç”ŸæˆæŸ¥è¯¢")
            else:
                logger.info("ğŸ“ ä½¿ç”¨è§„åˆ™ç”ŸæˆæŸ¥è¯¢")
            queries = query_generator.generate_batch(data_loader.patents)
            if use_llm:
                _save_query_cache(config, data_loader.patents, queries)
            logger.info(f"âœ… ç”Ÿæˆäº† {len(queries)} ä¸ªæŸ¥è¯¢" + ("å¹¶å·²å†™å…¥ç¼“å­˜" if use_llm else ""))
        tracker.end_step(step_start, f"å…± {len(queries)} ä¸ªæŸ¥è¯¢")

        # 3. åˆ›å»ºè´Ÿæ ·æœ¬é‡‡æ ·å™¨
        step_start = tracker.start_step("åˆ›å»ºè´Ÿæ ·æœ¬é‡‡æ ·å™¨")
        logger.info("å¼€å§‹åˆ›å»ºè´Ÿæ ·æœ¬é‡‡æ ·å™¨...")

        negative_sampler = create_negative_sampler(data_loader, config)

        logger.info(f"âœ… è´Ÿæ ·æœ¬é‡‡æ ·å™¨åˆ›å»ºå®Œæˆï¼Œç­–ç•¥: {config.negative.strategy}")
        tracker.end_step(step_start, f"è´Ÿæ ·æœ¬é‡‡æ ·å™¨åˆ›å»ºå®Œæˆ")

        # 4. æ„å»ºæ•°æ®é›†
        step_start = tracker.start_step("æ„å»ºè®­ç»ƒæ•°æ®é›†")
        logger.info("å¼€å§‹æ„å»ºæ•°æ®é›†...")

        dataset_builder = DatasetBuilder(
            config, query_generator, negative_sampler, data_loader
        )

        # ä¼ é€’å·²ç”Ÿæˆçš„æŸ¥è¯¢ï¼Œé¿å…é‡å¤ç”Ÿæˆ
        dataset = dataset_builder.build_dataset(
            use_cache=args.use_cache,
            pre_generated_queries=queries  # ä¼ é€’æ­¥éª¤2ç”Ÿæˆçš„æŸ¥è¯¢
        )

        # ä¿å­˜æ•°æ®é›†
        dataset_files = dataset_builder.save_dataset(
            os.path.join(config.experiment.output_dir, "datasets")
        )

        logger.info(f"âœ… æ•°æ®é›†æ„å»ºå®Œæˆ")
        tracker.end_step(step_start, "æ•°æ®é›†æ„å»ºå®Œæˆ")

        # 5. åˆ›å»ºPyTorchæ•°æ®é›†
        step_start = tracker.start_step("åˆ›å»ºPyTorchæ•°æ®é›†")
        logger.info("å¼€å§‹åˆ›å»ºPyTorchæ•°æ®é›†...")

        # åˆ›å»ºæ¨¡å‹ï¼ˆç”¨äºè·å–tokenizerï¼‰
        model = create_model(config)
        tokenizer = model.embedding_model.tokenizer

        # åˆ›å»ºæ•°æ®é›†ï¼ˆBGE æ¨èï¼šquery åŠ  instructionï¼Œpassage ä¸åŠ ï¼‰
        query_instruction = getattr(config.model, 'query_instruction_for_retrieval', None) or ""
        train_dataset = PatentDataset(
            dataset['train'],
            tokenizer,
            max_length=config.model.max_seq_length,
            query_instruction=query_instruction
        )

        val_dataset = PatentDataset(
            dataset['val'],
            tokenizer,
            max_length=config.model.max_seq_length,
            query_instruction=query_instruction
        )

        test_dataset = PatentDataset(
            dataset['test'],
            tokenizer,
            max_length=config.model.max_seq_length,
            query_instruction=query_instruction
        ) if dataset.get('test') else None

        logger.info(f"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ")
        logger.info(f"  è®­ç»ƒé›†: {len(train_dataset)} ä¸ªæ ·æœ¬")
        logger.info(f"  éªŒè¯é›†: {len(val_dataset)} ä¸ªæ ·æœ¬")
        if test_dataset:
            logger.info(f"  æµ‹è¯•é›†: {len(test_dataset)} ä¸ªæ ·æœ¬")

        tracker.end_step(step_start, f"åˆ›å»ºäº† {len(train_dataset)} ä¸ªè®­ç»ƒæ ·æœ¬")

        # 6. è®­ç»ƒæ¨¡å‹
        if not args.test_only:
            step_start = tracker.start_step("è®­ç»ƒæ¨¡å‹")
            logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹...")

            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = create_trainer(
                config, model, train_dataset, val_dataset, test_dataset
            )

            # æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæŒ‡å®šï¼‰
            if args.resume:
                logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
                trainer.load_checkpoint(args.resume)

            # å¼€å§‹è®­ç»ƒ
            logger.info("å¼€å§‹è®­ç»ƒè¿‡ç¨‹...")
            training_results = trainer.train()

            logger.info("âœ… è®­ç»ƒå®Œæˆ!")
            logger.info(f"  æœ€ä½³æ¨¡å‹: {training_results['best_model_path']}")
            logger.info(f"  æœ€ç»ˆæ¨¡å‹: {training_results['final_model_path']}")
            logger.info(f"  æœ€ä½³éªŒè¯æŸå¤±: {training_results['best_val_loss']:.4f}")

            tracker.end_step(step_start, "æ¨¡å‹è®­ç»ƒå®Œæˆ")
        else:
            logger.info("â­ï¸  è·³è¿‡è®­ç»ƒæ­¥éª¤ï¼ˆä»…æµ‹è¯•æ¨¡å¼ï¼‰")

        # 7. æµ‹è¯•æ¨¡å‹
        step_start = tracker.start_step("æµ‹è¯•æ¨¡å‹")
        logger.info("å¼€å§‹æµ‹è¯•æ¨¡å‹...")

        if args.test_only:
            # ä»…æµ‹è¯•æ¨¡å¼ï¼šåŠ è½½æœ€ä½³æ¨¡å‹
            best_model_path = os.path.join(config.experiment.output_dir, "best_model")
            if os.path.exists(best_model_path):
                model = PatentEmbeddingModel.from_pretrained(best_model_path, config)
                logger.info(f"ğŸ” ä» {best_model_path} åŠ è½½æ¨¡å‹è¿›è¡Œæµ‹è¯•")
            else:
                logger.warning("âš ï¸  æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼Œä½¿ç”¨æ–°åˆ›å»ºçš„æ¨¡å‹")
                model = create_model(config)

        # åˆ›å»ºè®­ç»ƒå™¨è¿›è¡Œæµ‹è¯•
        trainer = create_trainer(config, model, train_dataset, val_dataset, test_dataset)

        # æµ‹è¯•
        test_results = trainer.test()

        if test_results:
            logger.info("âœ… æµ‹è¯•å®Œæˆ!")
            logger.info(f"  æµ‹è¯•å‡†ç¡®ç‡: {test_results['accuracy']:.4f}")
            logger.info(f"  æµ‹è¯•ç›¸ä¼¼åº¦å·®è·: {test_results['sim_gap']:.4f}")
        else:
            logger.warning("âš ï¸  æ²¡æœ‰æµ‹è¯•ç»“æœ")

        tracker.end_step(step_start, "æ¨¡å‹æµ‹è¯•å®Œæˆ")

        # 8. ä¿å­˜æœ€ç»ˆé…ç½®
        step_start = tracker.start_step("ä¿å­˜é…ç½®å’Œç»“æœ")
        config_path = os.path.join(config.experiment.output_dir, "final_config.json")
        config.save(config_path)
        logger.info(f"âœ… æœ€ç»ˆé…ç½®å·²ä¿å­˜åˆ°: {config_path}")

        # ä¿å­˜è¿è¡Œæ‘˜è¦
        summary_path = os.path.join(config.experiment.output_dir, "run_summary.txt")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ä¸“åˆ©Embeddingæ¨¡å‹å¾®è°ƒ - è¿è¡Œæ‘˜è¦\n")
            f.write("=" * 60 + "\n")
            f.write(f"è¿è¡Œæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•°æ®ç›®å½•: {config.data.raw_data_dir}\n")
            f.write(f"ä¸“åˆ©æ•°é‡: {len(data_loader.patents)}\n")
            f.write(f"è®­ç»ƒæ ·æœ¬: {len(train_dataset)}\n")
            f.write(f"è´Ÿæ ·æœ¬ç­–ç•¥: {config.negative.strategy}\n")
            f.write(f"æŸ¥è¯¢ç”Ÿæˆæ–¹å¼: {'LLM' if config.query.use_llm else 'è§„åˆ™'}\n")
            if test_results:
                f.write(f"æµ‹è¯•å‡†ç¡®ç‡: {test_results['accuracy']:.4f}\n")
                f.write(f"ç›¸ä¼¼åº¦å·®è·: {test_results['sim_gap']:.4f}\n")
            f.write("=" * 60 + "\n")

        logger.info(f"âœ… è¿è¡Œæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_path}")
        tracker.end_step(step_start, "é…ç½®å’Œç»“æœä¿å­˜å®Œæˆ")

        # æ‰“å°æ€»è€—æ—¶
        tracker.summary()

        logger.info("=" * 60)
        logger.info("ğŸ‰ æ‰€æœ‰æ­¥éª¤å®Œæˆ!")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


def test_quick():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¿«é€Ÿæµ‹è¯•æ¨¡å¼...")

    test_args = [
        sys.argv[0],
        "--quick_test",
        "--output_dir", os.path.join(str(_project_root), "test_output"),
        "--negative_strategy", "optimized_mixed",
        "--log_level", "INFO"
    ]
    if len(sys.argv) > 1 and not sys.argv[1].startswith("--"):
        test_args.extend(["--data_dir", sys.argv[1]])

    sys.argv = test_args

    print("ğŸ”§ æµ‹è¯•é…ç½®: æœ€å¤§æ ·æœ¬æ•°=100, è®­ç»ƒè½®æ•°=2, æ‰¹æ¬¡å¤§å°=4, è´Ÿæ ·æœ¬ç­–ç•¥=optimized_mixed")
    main()


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æ˜¯å°æ•°æ®é›†æµ‹è¯•æ¨¡å¼
    if len(sys.argv) > 1 and sys.argv[1] == "--quick_test":
        # ç§»é™¤å‚æ•°ï¼Œé¿å…é‡å¤è§£æ
        sys.argv.remove("--quick_test")
        test_quick()
    elif len(sys.argv) == 1:
        # æ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œè¯¢é—®ç”¨æˆ·
        print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. å®Œæ•´è®­ç»ƒ")
        print("2. å¿«é€Ÿæµ‹è¯•ï¼ˆå°æ•°æ®é›†ï¼‰")
        print("3. ä»…æµ‹è¯•æ¨¡å¼")

        choice = input("è¯·è¾“å…¥é€‰æ‹© (1, 2æˆ–3): ").strip()

        if choice == "2":
            test_quick()
        elif choice == "3":
            sys.argv = [sys.argv[0], "--test_only"]
            main()
        else:
            main()
    else:
        # æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç›´æ¥è¿è¡Œä¸»å‡½æ•°
        main()